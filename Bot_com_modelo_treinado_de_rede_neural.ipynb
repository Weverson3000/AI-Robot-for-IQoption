{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Weverson3000/AI-Robot-for-IQoption/blob/main/Bot_com_modelo_treinado_de_rede_neural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPKn_felO64S",
        "outputId": "b9726aee-9f42-4bb4-a305-041d8b571997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: iqoptionapi in /usr/local/lib/python3.10/dist-packages (6.8.9.1)\n",
            "Requirement already satisfied: pylint in /usr/local/lib/python3.10/dist-packages (from iqoptionapi) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from iqoptionapi) (2.31.0)\n",
            "Requirement already satisfied: websocket-client==0.56 in /usr/local/lib/python3.10/dist-packages (from iqoptionapi) (0.56.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from websocket-client==0.56->iqoptionapi) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pylint->iqoptionapi) (4.2.0)\n",
            "Requirement already satisfied: astroid<=3.2.0-dev0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from pylint->iqoptionapi) (3.1.0)\n",
            "Requirement already satisfied: isort!=5.13.0,<6,>=4.2.5 in /usr/local/lib/python3.10/dist-packages (from pylint->iqoptionapi) (5.13.2)\n",
            "Requirement already satisfied: mccabe<0.8,>=0.6 in /usr/local/lib/python3.10/dist-packages (from pylint->iqoptionapi) (0.7.0)\n",
            "Requirement already satisfied: tomlkit>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from pylint->iqoptionapi) (0.12.4)\n",
            "Requirement already satisfied: dill>=0.2 in /usr/local/lib/python3.10/dist-packages (from pylint->iqoptionapi) (0.3.8)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pylint->iqoptionapi) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->iqoptionapi) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->iqoptionapi) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->iqoptionapi) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->iqoptionapi) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from astroid<=3.2.0-dev0,>=3.1.0->pylint->iqoptionapi) (4.11.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install iqoptionapi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAkmnBQ3Ql6d",
        "outputId": "7d5ad364-1a34-4584-a96f-21f1fba60016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Lu-Yi-Hsun/iqoptionapi.git\n",
            "  Cloning https://github.com/Lu-Yi-Hsun/iqoptionapi.git to /tmp/pip-req-build-bd_bfyfh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Lu-Yi-Hsun/iqoptionapi.git /tmp/pip-req-build-bd_bfyfh\n",
            "  Resolved https://github.com/Lu-Yi-Hsun/iqoptionapi.git to commit e2a198fe74a3cd646604b11d293c383ef3d39330\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pylint (from iqoptionapi==6.8.9.1)\n",
            "  Downloading pylint-3.1.0-py3-none-any.whl (515 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.6/515.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from iqoptionapi==6.8.9.1) (2.31.0)\n",
            "Collecting websocket-client==0.56 (from iqoptionapi==6.8.9.1)\n",
            "  Downloading websocket_client-0.56.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from websocket-client==0.56->iqoptionapi==6.8.9.1) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pylint->iqoptionapi==6.8.9.1) (4.2.0)\n",
            "Collecting astroid<=3.2.0-dev0,>=3.1.0 (from pylint->iqoptionapi==6.8.9.1)\n",
            "  Downloading astroid-3.1.0-py3-none-any.whl (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.6/275.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort!=5.13.0,<6,>=4.2.5 (from pylint->iqoptionapi==6.8.9.1)\n",
            "  Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mccabe<0.8,>=0.6 (from pylint->iqoptionapi==6.8.9.1)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting tomlkit>=0.10.1 (from pylint->iqoptionapi==6.8.9.1)\n",
            "  Downloading tomlkit-0.12.4-py3-none-any.whl (37 kB)\n",
            "Collecting dill>=0.2 (from pylint->iqoptionapi==6.8.9.1)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pylint->iqoptionapi==6.8.9.1) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->iqoptionapi==6.8.9.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->iqoptionapi==6.8.9.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->iqoptionapi==6.8.9.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->iqoptionapi==6.8.9.1) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from astroid<=3.2.0-dev0,>=3.1.0->pylint->iqoptionapi==6.8.9.1) (4.11.0)\n",
            "Building wheels for collected packages: iqoptionapi\n",
            "  Building wheel for iqoptionapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iqoptionapi: filename=iqoptionapi-6.8.9.1-py3-none-any.whl size=57123 sha256=f15c2492fde0efee688bf0c6e50c9c1673c4b7e93e1b77b4e1f1431ff9a5e45f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4dl71gej/wheels/2b/b6/82/b6eba3f9743c25dae07efc4e7e1031742429f144f314063bcb\n",
            "Successfully built iqoptionapi\n",
            "Installing collected packages: websocket-client, tomlkit, mccabe, isort, dill, astroid, pylint, iqoptionapi\n",
            "  Attempting uninstall: websocket-client\n",
            "    Found existing installation: websocket-client 1.7.0\n",
            "    Uninstalling websocket-client-1.7.0:\n",
            "      Successfully uninstalled websocket-client-1.7.0\n",
            "Successfully installed astroid-3.1.0 dill-0.3.8 iqoptionapi-6.8.9.1 isort-5.13.2 mccabe-0.7.0 pylint-3.1.0 tomlkit-0.12.4 websocket-client-0.56.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/Lu-Yi-Hsun/iqoptionapi.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCKBtrRNC7XC"
      },
      "source": [
        "# Melhor modelo IA para IQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exVpbl_Y84QH"
      },
      "source": [
        "# Modelo 3 de ia para iqoption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ-4svKZpzCE",
        "outputId": "f658e24a-f898-464c-ec57-b2e0a1f8ec85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3_eYmmvzDMd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/iqoptionapi')\n",
        "\n",
        "from iqoptionapi.stable_api import IQ_Option\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import pickle\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "from iqoptionapi.stable_api import IQ_Option\n",
        "\n",
        "\n",
        "# Define o caminho do arquivo de treinamento\n",
        "training_file = \"/content/gdrive/My Drive/iqoptionapi/pretrained_model.pkl\"\n",
        "\n",
        "model = None  # Definir model como None inicialmente\n",
        "\n",
        "# Verifica se o arquivo de treinamento existe\n",
        "if os.path.exists(training_file):\n",
        "    # Carrega o modelo pré-treinado do arquivo\n",
        "    with open(training_file, 'rb') as file:\n",
        "        pretrained_model = pickle.load(file)\n",
        "    print(\"Modelo pré-treinado carregado com sucesso!\")\n",
        "    # Usa o modelo pré-treinado para treinamento\n",
        "    model = pretrained_model\n",
        "else:\n",
        "\n",
        "  print('Iniciando...')\n",
        "\n",
        "# Conectar à API da IQ Option\n",
        "API = IQ_Option('e-mail', 'senha')\n",
        "API.connect()\n",
        "\n",
        "API.change_balance('PRACTICE') # PRACTICE / REAL\n",
        "\n",
        "if API.check_connect():\n",
        "    print('Conectado com sucesso!')\n",
        "else:\n",
        "    print('Erro ao conectar')\n",
        "    input('\\n\\n Aperte enter para sair')\n",
        "    sys.exit()\n",
        "\n",
        "#redeneural configuracao=========================================================================================\n",
        "\n",
        "\n",
        "BIAS = 1\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_dx(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "# Definir uma função de ativação de limiar\n",
        "def threshold_activation(output, media_saidas):\n",
        "    threshold = media_saidas  # Define um limiar de 500 para decidir entre call ou put\n",
        "    return 'call' if output >= threshold else 'put'\n",
        "\n",
        "    def cost_derivative(self, output_activations, y):\n",
        "        \"\"\"Retorna o vetor das derivadas parciais da função de custo.\n",
        "\n",
        "        output_activations é a saída atual da rede neural,\n",
        "        y é a saída desejada.\n",
        "        \"\"\"\n",
        "        # Calcula a derivada parcial da função de custo\n",
        "        cost_derivative = output_activations - y\n",
        "\n",
        "        # Penaliza os resultados negativos, adicionando uma penalidade\n",
        "        # proporcional à magnitude do valor negativo\n",
        "        if output_activations < 0:\n",
        "            # Aumente o valor dessa penalidade conforme necessário para\n",
        "            # ajustar o comportamento da rede\n",
        "            penalty = 0.5  # Valor de penalidade arbitrário\n",
        "            cost_derivative += penalty * output_activations\n",
        "\n",
        "        return cost_derivative\n",
        "\n",
        "def salvar_modelo(self, nome_arquivo):\n",
        "     # Salvar o modelo da rede neural\n",
        "    with open(nome_arquivo, 'wb') as arquivo:\n",
        "        pickle.dump(self, arquivo)\n",
        "    print(\"Modelo salvo como\", nome_arquivo)\n",
        "\n",
        "class Neuronio:\n",
        "    def __init__(self, quantidade_ligacoes):\n",
        "        self.peso = np.random.randint(-1000, 1000, quantidade_ligacoes) / 1000.0\n",
        "        self.erro = 0\n",
        "        self.saida = 1\n",
        "\n",
        "class Camada:\n",
        "    def __init__(self, quantidade_neuronios, quantidade_ligacoes):\n",
        "        self.neuronios = [Neuronio(quantidade_ligacoes) for _ in range(quantidade_neuronios)]\n",
        "\n",
        "class RedeNeural:\n",
        "    def __init__(self, quantidade_escondidas, qtd_neuronios_entrada, qtd_neuronios_escondida, qtd_neuronios_saida, resultado_rede_neural, saida_desejada):\n",
        "        self.camada_entrada = Camada(qtd_neuronios_entrada + BIAS, qtd_neuronios_entrada)\n",
        "        self.camada_escondida = [Camada(qtd_neuronios_escondida + BIAS, qtd_neuronios_entrada) for _ in range(quantidade_escondidas)]\n",
        "        self.camada_saida = Camada(qtd_neuronios_saida, qtd_neuronios_escondida)\n",
        "\n",
        "    def copiar_vetor_para_camadas(self, vetor):\n",
        "        j = 0\n",
        "        for camada in self.camada_escondida:\n",
        "            for neuronio in camada.neuronios:\n",
        "                neuronio.peso = vetor[j:j+len(neuronio.peso)]\n",
        "                j += len(neuronio.peso)\n",
        "        for neuronio in self.camada_saida.neuronios:\n",
        "            neuronio.peso = vetor[j:j+len(neuronio.peso)]\n",
        "            j += len(neuronio.peso)\n",
        "\n",
        "    def copiar_para_entrada(self, vetor_entrada):\n",
        "        for i, neuronio in enumerate(self.camada_entrada.neuronios[:-BIAS]):\n",
        "            neuronio.saida = vetor_entrada[i]\n",
        "\n",
        "    def quantidade_pesos(self):\n",
        "        soma = sum(len(neuronio.peso) for camada in self.camada_escondida for neuronio in camada.neuronios)\n",
        "        soma += sum(len(neuronio.peso) for neuronio in self.camada_saida.neuronios)\n",
        "        return soma\n",
        "\n",
        "    def copiar_da_saida(self):\n",
        "        return [neuronio.saida for neuronio in self.camada_saida.neuronios]\n",
        "\n",
        "    def calcular_saida(self):\n",
        "        for i, neuronio in enumerate(self.camada_escondida[0].neuronios[:-BIAS]):\n",
        "            somatorio = np.sum(neuronio.saida * [n.saida for n in self.camada_entrada.neuronios])\n",
        "            self.camada_escondida[0].neuronios[i].saida = relu(somatorio)\n",
        "\n",
        "        for k in range(1, len(self.camada_escondida)):\n",
        "            for i, neuronio in enumerate(self.camada_escondida[k].neuronios[:-BIAS]):\n",
        "                somatorio = np.sum(neuronio.saida * [n.saida for n in self.camada_escondida[k-1].neuronios])\n",
        "                self.camada_escondida[k].neuronios[i].saida = relu(somatorio)\n",
        "\n",
        "        for i, neuronio in enumerate(self.camada_saida.neuronios):\n",
        "            somatorio = np.sum(neuronio.saida * [n.saida for n in self.camada_escondida[-1].neuronios])\n",
        "            self.camada_saida.neuronios[i].saida = relu(somatorio)\n",
        "\n",
        "    def update_mini_batch(self, mini_batch, eta):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "\n",
        "        self.weights = [w-(eta/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)]\n",
        "        self.biases = [b-(eta/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)]\n",
        "\n",
        "    def backprop(self, x, y):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "\n",
        "        # Feedforward\n",
        "        activation = x\n",
        "        activations = [x]\n",
        "        zs = []\n",
        "\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            z = np.dot(w, activation)+b\n",
        "            zs.append(z)\n",
        "            activation = relu(z)\n",
        "            activations.append(activation)\n",
        "\n",
        "        delta = self.cost_derivative(resultado_rede_neural, saida_desejada)\n",
        "        #delta = self.cost_derivative(activations[-1], y) * relu_dx(zs[-1])\n",
        "        nabla_b[-1] = delta\n",
        "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
        "\n",
        "        for l in range(2, self.num_layers):\n",
        "            z = zs[-l]\n",
        "            sp = relu_dx(z)\n",
        "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
        "            nabla_b[-l] = delta\n",
        "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
        "\n",
        "        return (nabla_b, nabla_w)\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
        "        return sum(int(x > 0) for (x, y) in test_results)\n",
        "\n",
        "    def salvar_modelo(self, nome_arquivo):\n",
        "        # Code to save the neural network model to a file named nome_arquivo\n",
        "        # Train the neural network\n",
        "        np.save(nome_arquivo, self)\n",
        "        print(\"Modelo salvo como\", nome_arquivo)\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "global v1\n",
        "v1 = 0\n",
        "acumulador_saidas = 0\n",
        "contador = 0\n",
        "conta_mediana = 0\n",
        "banca = 0\n",
        "loss = 0\n",
        "wins = 0\n",
        "epoca = 0\n",
        "checkpoint_interval = 50  # Definindo o intervalo de checkpoint para salvar o modelo\n",
        "global Entrada\n",
        "Entrada = 2\n",
        "limite_banca = 30\n",
        "while True:\n",
        "    # Code for gathering candlestick data, processing it, and preparing input vectors\n",
        "\n",
        "    # Verificar se o arquivo de treinamento existe\n",
        "    if os.path.exists(training_file):\n",
        "        # Carregar o modelo pré-treinado do arquivo\n",
        "        with open(training_file, 'rb') as file:\n",
        "            pretrained_model = pickle.load(file)\n",
        "        print(\"Modelo pré-treinado carregado com sucesso!\")\n",
        "        # Usar o modelo pré-treinado para treinamento\n",
        "        model = pretrained_model\n",
        "    else:\n",
        "\n",
        "        if __name__ == \"__main__\":\n",
        "            # Exemplo de uso\n",
        "            quantidade_escondidas = 2\n",
        "            qtd_neuronios_entrada = 6\n",
        "            qtd_neuronios_escondida = 2\n",
        "            qtd_neuronios_saida = 1\n",
        "\n",
        "            Paridade = 'EURUSD-OTC'\n",
        "            if contador % checkpoint_interval == 0 and contador != 0:\n",
        "                # Salvar o modelo da rede neural\n",
        "                print(\"Salvando modelo no checkpoint \", contador)\n",
        "                nome_arquivo = \"modelo_checkpoint_\" + str(contador) + \".npy\"\n",
        "                rede.salvar_modelo(nome_arquivo)\n",
        "                contador = 0\n",
        "                media_saidas = 0\n",
        "                banca = 0\n",
        "                loss = 0\n",
        "                wins = 0\n",
        "                epoca = epoca + 1\n",
        "\n",
        "\n",
        "            #Obter velas (candles)\n",
        "            #print(\"Obtendo velas...\")\n",
        "            #print(API.get_candles(Paridade, 60, 111, time.time()))\n",
        "\n",
        "            print(\"Obtendo velas...\")\n",
        "            candles = API.get_candles(Paridade, 60, 111, time.time())  # Substitua 'EURUSD' pela paridade desejada\n",
        "\n",
        "\n",
        "\n",
        "            #tendência\n",
        "\n",
        "            candles = API.get_candles(Paridade, 60, 5, time.time())\n",
        "\n",
        "            # Calculando a tendência\n",
        "            prices = [candle['close'] for candle in candles]\n",
        "            trend = \"ascendente\" if prices[-1] > prices[0] else \"descendente\"\n",
        "            n6 = 100 if prices[-1] > prices[0] else 0\n",
        "            print(f\"A tendência para {Paridade} é {trend}\")\n",
        "\n",
        "            # humor dos traders\n",
        "\n",
        "            tipo = \"turbo-option\"  # O tipo de opção (pode ser \"forex\", \"turbo-option\", etc.)\n",
        "\n",
        "            API.start_mood_stream(Paridade)  # Inicia o stream do humor dos traders\n",
        "\n",
        "            humor_traders = API.get_traders_mood(Paridade)  # Obtém o humor dos traders\n",
        "            #print(f\"Humor dos traders para {Paridade}: {humor_traders}\")\n",
        "\n",
        "            #API.stop_mood_stream(Paridade)  # Para o stream do humor dos traders\n",
        "\n",
        "            n7 = float(humor_traders * 100)\n",
        "\n",
        "            # Imprime o volume da vela mais recente\n",
        "            #print(\"Volume:\", candles[-1]['open'])\n",
        "\n",
        "            # Imprime o volume da vela mais recente\n",
        "            #print(\"Volume:\", candles[-1]['close'])\n",
        "\n",
        "            # Imprime o volume da vela mais recente\n",
        "            #print(\"Volume:\", candles[-1]['max'])\n",
        "\n",
        "            #n1 = candles[-1]['open'] + candles[0]['open'] + candles[1]['open']\n",
        "            #n2 = candles[-1]['close'] + candles[0]['close'] + candles[1]['close']\n",
        "            #n3 = candles[-1]['max'] + candles[0]['max'] + candles[1]['max']\n",
        "            #n4 = candles[-1]['min'] + candles[0]['min'] + candles[1]['min']\n",
        "            n1 = candles[-1]['open']\n",
        "            n2 = candles[0]['min']\n",
        "            n3 = candles[1]['max']\n",
        "            n4 = candles[2]['close']\n",
        "            #n5 = candles[3]['volume']\n",
        "            #Verificar o resultado de uma opção digital\n",
        "\n",
        "\n",
        "            #vetor_entrada = [n1, n2, n3, n4, n5, n6, n7]\n",
        "\n",
        "            #========Normalizacao dos DADOS==========================================================\n",
        "\n",
        "            # Dados\n",
        "            data = np.array([n1, n2, n3, n4, n6, n7])\n",
        "\n",
        "            # Min-Max Scaling\n",
        "            min_val = np.min(data)\n",
        "            max_val = np.max(data)\n",
        "            vetor_entrada = (data - min_val) / (max_val - min_val)\n",
        "\n",
        "            #print(\"Dados originais:\", data)\n",
        "            #print(\"Dados normalizados:\", scaled_data)\n",
        "\n",
        "\n",
        "\n",
        "            #========Normalizacao dos DADOS==========================================================\n",
        "\n",
        "\n",
        "            #soros = Entrada * 0.85\n",
        "\n",
        "            Tempografico = 1 # 1/5/15\n",
        "\n",
        "            all_profit = API.get_all_profit()\n",
        "            profit = all_profit[Paridade]['turbo']  # Isola o valor de lucro para 'turbo'\n",
        "            Lucro = float(profit)\n",
        "\n",
        "\n",
        "            resultado_rede_neural = v1  # Substitua v1 pelo valor real produzido pela rede neural\n",
        "            saida_desejada = Lucro*10\n",
        "\n",
        "            # Chame a função cost_derivative com os valores apropriados\n",
        "\n",
        "            rede = RedeNeural(quantidade_escondidas, qtd_neuronios_entrada, qtd_neuronios_escondida, qtd_neuronios_saida, resultado_rede_neural, saida_desejada)\n",
        "            rede.copiar_para_entrada(vetor_entrada)\n",
        "            rede.calcular_saida()\n",
        "            saida = rede.copiar_da_saida()\n",
        "            print(\"Saída da rede neural:\", saida)\n",
        "\n",
        "\n",
        "            #Fim da REDE NEURAL========================================================================================================\n",
        "        num = float(saida[0])\n",
        "        acumulador_saidas += num\n",
        "        contador += 1\n",
        "        conta_mediana += 1\n",
        "        media_saidas = acumulador_saidas / contador\n",
        "        print(\"media das saida:\", media_saidas)\n",
        "\n",
        "        if contador == 25:\n",
        "            acumulador_saidas = 0\n",
        "\n",
        "\n",
        "        if API.check_connect() == False:\n",
        "            print('Erro ao conectar')\n",
        "            input('\\n\\n Aperte enter para sair')\n",
        "            sys.exit()\n",
        "        else:\n",
        "\n",
        "\n",
        "          # Usar a função de ativação para obter a decisão comercial\n",
        "            Direcao =  threshold_activation(num , media_saidas)\n",
        "            check, id = API.buy(Entrada, Paridade, Direcao, Tempografico)\n",
        "            time.sleep(0.5)\n",
        "            print(API.check_win_v3(id))\n",
        "            v1 = API.check_win_v3(id)\n",
        "\n",
        "            #nova\n",
        "\n",
        "            #print('Valor do Soros = ',soros)\n",
        "            #print('Valor do Entrada 1 = ',Entrada)\n",
        "\n",
        "            if v1 > 1 or v1 < -35:\n",
        "              wins = wins + 1\n",
        "              #Entrada = 2\n",
        "            else:\n",
        "                if v1 == 0:\n",
        "                  Entrada # Entrada repete\n",
        "                else:\n",
        "                  loss = loss + 1\n",
        "                  #Entrada = Entrada*2.5\n",
        "\n",
        "            banca = v1 + banca\n",
        "            print('Epoca =', epoca)\n",
        "            print('Valor da banca com', contador, 'operacoes', banca, 'Wins =', wins, 'Loss =', loss)\n",
        "\n",
        "                # Verificar se é hora de fazer um checkpoint do modelo\n",
        "            if epoca % checkpoint_interval == 0:\n",
        "                # Salvar o modelo atual como um checkpoint\n",
        "                nome_arquivo_checkpoint = f\"modelo_checkpoint_{epoca}.pkl\"\n",
        "                model.salvar_modelo(nome_arquivo_checkpoint)\n",
        "                print(f\"Modelo salvo como {nome_arquivo_checkpoint}\")\n",
        "\n",
        "            # Verificar se a banca está abaixo de um limite mínimo\n",
        "            if banca <= limite_banca:\n",
        "                print(\"A banca atingiu o limite mínimo. Encerrando o programa.\")\n",
        "                break\n",
        "\n",
        "            #print('Valor do Entrada 3 = ',Entrada)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HuvI84LgeusEhA0dxaC1hRezqvxji0g2",
      "authorship_tag": "ABX9TyMYhSXYjA0KY46kuvPnfYZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}